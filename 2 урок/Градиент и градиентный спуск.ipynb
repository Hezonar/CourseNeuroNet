{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня поговорим о таком понятии, как градиент. Он нужен, чтобы находить параметры (веса) нашей сети.  \n",
    "Как их найти? Если вспомним материалы ранее, то поймем, что веса мы ищем такие, чтобы минимизировать наш функционал качества.\n",
    "Как минимизировать функционал качества? Конечно же найти производную... Если мы имеем всего 1 параметр.  \n",
    "Однако если весов куда больше, чем 1, то на помощь нам поможет **\"производная\" для n-мерного измерения, и называется она - градиент**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель\n",
    "Рассмотрим первую простую модель линейной регрессии, которая выглядит так:\n",
    "$$\n",
    "y = \\sum_{i=1}^{n} w_ix_i + b,\n",
    "$$\n",
    "где $x_i$ - входы модели, $y$ - выход, $w_i$ и $b$ - параметры модели, которые мы будем обучать.\n",
    "\n",
    "Заметим, что сумма $\\sum_{i=1}^{n} w_ix_i$ является скалярным произведением векторов $\\vec{w} = (w_1, w_2, ..., w_n)$ и $\\vec{x} = (x_1, x_2, ..., x_n)$, поэтому нашу модель можно записать проще:\n",
    "\\begin{equation*}\n",
    "y = \\vec{w}^T \\vec{x} + b\n",
    "\\end{equation*}\n",
    "\n",
    "Проделаем, небольшой трюк, который ещё больше облегчит запись. Для этого перенесём смещение $b$ в конец вектора $\\vec{w}$, а в $\\vec{x}$ допишем фиктивную единицу, получим $\\vec{w} = (w_1, w_2, ..., w_n, b)$, $\\vec{x} = (x_1, x_2, ..., x_n, 1)$. Таким образом, придём к записи:\n",
    "\\begin{equation*}\n",
    "y = \\vec{w}^T \\vec{x}\n",
    "\\tag{1}\n",
    "\\end{equation*}\n",
    "В дальнейшем в качестве нашей модели будем использовать именно последнее вырадение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функционал потерь\n",
    "\n",
    "Пусть имеется выборка $X^{N} = (x_i)^{N}_{i=1}, Y^N = (y_i)^N_{i=1}$. Воспользуемся описанной ранее функцией **среднеквадратической ошибки (MSE - Mean Squarred Error)**:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^N (y_i-g(x_i|\\theta))^2\n",
    "\\tag{2}\n",
    "\\end{equation*}$$,\n",
    "где $x_i$ - входной вектор размера n. $y_i$ - ответ в виде числа, $g(x_i|\\theta)$ - модель, $\\theta$ - параметры модели. Подставив линейную регрессию (1) вместо модели $g$ в наш функционал потерь получим:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "MSE = \\frac{1}{N} \\sum_{i=1}^N (y_i-\\vec{w}^T \\vec{x_i})^2\n",
    "\\tag{3}\n",
    "\\end{equation*}$$\n",
    "\n",
    "Большинство алгоритмов машинного обучения в том или ином виде включает оптимизацию, т.е. нахождение минимума или максимума функции f(x) при изменении x. Обычно задачу оптимизации формулируют в терминах нахождения минимума. Для нахождения максимума достаточно применить алгоритм минимизации к функции –f(x). Функция, для которой мы ищем минимум или максимум, называется *целевой функцией*. Если речь идет о минимизации, то употребляют также \n",
    "термины *функция стоимости*, *функция потерь* или *функция ошибок*. В этом курсе все эти термины будут использоваться как синонимы.\n",
    "\n",
    "Мы дожны спроектировать алгоритм машинного обучения, который, наблюдая обучающую выборку $X^N, Y^N$, улучшает веса модели $\\vec{w}$ таким образом, чтобы функционал качетва MSE был наименьшим. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Небольшое отступление\n",
    "\n",
    "Предполагается, что слушатели курса знакомы с основами математического анализа и линейной алгебры, но всё же сделаем краткий обзор некоторых необходимых понятий. \n",
    "\n",
    "Пусть дана дифференцируемая функция $f(x)$. Точки, в которых $f′(x) = 0$, называются *критическими*, или *стационарными*. \n",
    "\n",
    "*Локальным минимумом* называется точка, в которой $f(x)$ меньше, чем во всех точках \n",
    "малой окрестности, поэтому уменьшить $f(x)$ путем изменения аргумента $x$ на небольшую величину невозможно. *Локальным максимумом* называется точка, в которой $f(x)$ больше, чем во всех точках малой окрестности, поэтому невозможно увеличить $f(x)$ путем изменения аргумента $x$ на небольшую величину. Некоторые критические \n",
    "точки не являются ни минимумами, ни максимумами. Они называются *седловыми\n",
    "точками*. Далее на рис. показаны примеры всех критических точек.\n",
    "\n",
    "Для функций нескольких переменных следует ввести понятие частной производной. Пусть $f(x_1, x_2, ..., x_n)$ - функция от нескольких переменных. Для удобства введём вектор $x = (x_1, x_2, ..., x_n)$. \n",
    "\n",
    "*Частная производная* $\\delta/\\delta x_i f(x)$ показывает, как изменяется $f$ при изменении \n",
    "аргумента $x$ только в одном направлении $x_i$. *Градиент* обобщает понятие производной \n",
    "на вектор: *градиентом* функции $f$ называется вектор всех ее частных производных, \n",
    "он обозначается $\\nabla_x f(x)$. i-м элементом градиента является частная производная $f$ по \n",
    "$x_i$: \n",
    "\n",
    "$$\\nabla_x f(x) = (\\frac{\\delta f}{\\delta x_1}, \\frac{\\delta f}{\\delta x_2}, ..., \\frac{\\delta f}{\\delta x_n}).$$ \n",
    "\n",
    "В многомерном случае критическими называются точки, в которых все элементы \n",
    "градиента равны 0.\n",
    "\n",
    "И, наконец, запишем несколько полезных свойств градиента:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_w \\vec w^T \\vec a =  \\vec a\n",
    "\\tag{4}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_w \\vec w^T \\vec w = 2 \\vec w\n",
    "\\tag{5}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\vec w} \\vec w^TA \\vec w = (A+A^T) \\vec w\n",
    "\\tag{6}\n",
    "\\end{equation*}\n",
    "\n",
    "Где $a, w$ - векторы длины $n$, $A$ - матрица $n \\times n$. Предлагается доказать данные свойства самостоятельно в качестве упражнения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Точная формула\n",
    "\n",
    "Для минимизации MSE мы можем просто приравнять градиент по w к 0 и решить получившееся уравнение:\n",
    "$$\\nabla_{\\vec{w}} MSE = 0$$\n",
    "$$\\nabla_{\\vec{w}} \\frac{1}{N} \\sum_{i=1}^N (\\vec{w}^T \\vec{x_i}-y_i)^2  = 0\n",
    "$$\n",
    "\n",
    "Перепишем уравнение в векторную форму, воспользовавшись умножением матриц $X=X^N, Y=Y^N$.\n",
    "$$\\nabla_{\\vec{w}}(X\\vec{w} - Y)^T(X\\vec{w}-Y)=0$$\n",
    "\n",
    "Раскрывая скобки, получаем:\n",
    "$$\\nabla_{\\vec{w}}(\\vec{w}^T X^T X \\vec w - \\vec w^TX^TY - Y^T \\vec w X + Y^T Y) = 0$$\n",
    "\n",
    "Возьмём градиент по $\\vec w$, пользуясь правилами (4)-(6).\n",
    "$$2X^T X \\vec w - 2X^T Y = 0$$\n",
    "$$\\vec w = (X^T X)^{-1} X^T Y$$\n",
    "\n",
    "Заметим, что обратная матрица $(X^T X)^{-1}$ может существовать не всегда. Для решения этой проблемы воспользуемся псевдоинверсией, обозначив её как $+$.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\vec w = (X^T X)^+ X^T Y\n",
    "\\tag{7}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так выглядит **градиент функции MSE**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td> <img src=\"images/MSE.png\" alt=\"Drawing\" style=\"width: 820px;height: 500px\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный спуск\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике точную формулу использовать неудобно. Во-первых обратной матрицы может и не существовать, а во-вторых вычисление обратной матрицы занимает n^3 итераций, где n-количество чисел в матрице. Так, например, чтобы вычислить обратную матрицу размером 1000x1000 нам потребуется 1000x1000x1000 операций($10^9$). Понятно что на практике матрицы могут быть и больше размерностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На помощь приходит такое понятие как **градиентный спуск**. Если говорить простым языком, то это можно **сравнить с тем, как мы спускаемся с горы**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, мы стоим на горе. Тогда мы должны **посчитать в какую сторону нам двигаться**, чтобы сделать шаг. Считается это очень просто, все так же с помощью градиента от функции. Мы получаем вектор, который указывает в сторону скорейшего возрастания. Берем его с минусом и получаем сторону скорейшего убывания. Именно в ее сторону нам нужно двигаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь **мы должны определиться насколько большим хотим сделать наш шаг**. С одной стороны, шагая медленно мы будем очень долго спускаться, но зато точно не пропустим наш минимум. С другой стороны, делая большие шаги, мы можем просто перешагнуть наш минимум и пойти дальше. Такие **параметры обычно подбираются вручную**. Поэтому в нейронных сетях их принято называть **гиперпараметры**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Давайте составим наш алгоритм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Выбираем насколько большие хотим делать наши шаги. По-другому это называется learning rate. То есть скорость обучения. $lr = const$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Выбираем случайные веса (нашу начальную точку с которой мы будем идти). $\\vec w = random$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Считаем антиградиент и шагаем в его сторону. Шаг мы делаем с помощью прибавления шага к нашей текущей точке: $\\vec w = \\vec w -\\nabla_{\\vec{w}}MSE * lr$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **Делаем предыдущий шаг**, либо до тех пор, **пока мы не достигнем минимума**, либо **пока у нас не закончится допустимое число шагов**. Это тоже является гиперпараметром, и нужен для того, чтобы остановить наше обучение, в случае если мы уйдем на графике в какое-нибудь плато. Соответственно, **если у нас слишком маленький шаг, то мы можем быстрее выйти из цикла из-за числа шагов, так и не достигнув минимума**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1) $\\nabla_{\\vec{w}}MSE * lr < \\epsilon$ - выход из цикла, когда достигнем минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2) for i in range(epochs) - выход из цикла, при определенном количестве шагов(эпох)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images\\gradient_descent_surf_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стохастический градиентный спуск\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но даже алгоритм выше будет не столь эффективен из-за того, что вычисляет градиент функции на каждом шаге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что, если **нам вычислять градиент не всех весов, а только одного** на каждом шаге? Тогда алгоритм будет работать достаточно быстро. Это можно сравнить, как если бы мы вычисляли средний рост студентов не по всей выборке студентов ВУЗа, а взяли лишь рандомного студента и измерили его рост."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из этого легко понять, что наш график будет вести себя совсем по другому, нежели с обычным градиетным спуском."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, у этого метода есть несколько больших плюсов:\n",
    "\n",
    "1) Он гораздо быстрее, нежели пользоваться обычным градиетным спуском.  \n",
    "2) Из-за своей особенности, он, возможно, пропустит локальные минимумы и найдет глобальный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь сравним сходимость двух алгоритмов:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images\\GD_trajectory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images\\SGD_trajectory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Побатчевый градиентный спуск\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как это было видно выше, это далеко не идеальный алгоритм. Попробуем пофиксить проблемы, прошлого алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое очевидное, это будет **использование не одного критерия для градиента, а сразу нескольких (batch)**. То есть теперь **мы выбираем не одного студента из ВУЗа и ищем его рост, а сразу нескольких студентов**. Это будет все еще намного быстрее, чем брать всю выборку целиком. Однако, это будет намного лучше, если брать 1 рандомного студента.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбирать размер batch нам придется самим, это может быть как 10 объектов из выборки, так и 1/5 нашей выборки. Чем больше это число, тем точнее, но дольше будет работать наш алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инерционный градиетный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из рисунка чуть выше, при обычном стохастическом градиентном спуске мы движемся совсем не к центру. Тогда **можно попробовать это исправить, складывая предыдущие результаты нашего градиента. Такой метод называется инерционным**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лучший градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы уже поняли, что методов оптимизации есть достаточно много. **Попытка собрать их все вместе была реализована в градиентном спуске, который называется Adam**. Он считается статистически лучшим спуском, однако это не говорит о том, что он подходит для всех задач. Можно сказать, что для выборки из всех задач будет лучший именной градиентный спуск Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/grad_spusk2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому в дальнейших задачах мы будем использовать именно Adam. Его формула выглядит следующим образом:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/Adam.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запоминать и понимать эту формулу совсем необязательно) Она уже встроена во все библиотеки. Важно лишь понимать, что в одной формуле собраны все приемы рассмотренные ранее и даже больше. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Если кто хочет дополнительно ознакомиться с методами градиентного спуска, есть статья на хабре - https://habr.com/ru/post/318970/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Там очень много методов, в том числе с иллюстрациями их работы. Может быть интересно."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
