{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/introdution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Основные понятия и определения\n",
    "Задано множество объектов $X$, множество допустимых ответов $Y$, и существует *целевая функция* (target function) $y^*: X \\to Y$, значения которой $y_i = y^*(x_i)$ известны только на конечном подмножестве объектов ${x_1,...,x_{\\ell}}\\subset X$. Пары «объект– ответ» $(x_i, y_i)$ называются *прецедентами*. Совокупность пар $X^{\\ell} = (x_i,y_i)^{\\ell}_{i=1}$ называется *обучающей выборкой* (training sample). \n",
    "\n",
    "Задача обучения *по прецедентам* заключается в том, чтобы по выборке $X_{\\ell}$ *восстановить зависимость* $y^∗$, то есть построить *решающую функцию* (decision function) $a: X \\to Y$, которая приближала бы целевую функцию $y^*(x)$, причём не только на объектах обучающей выборки, но и на всём множестве X. \n",
    "\n",
    "Решающая функция a должна допускать эффективную компьютерную реализацию; по этой причине будем называть её *алгоритмом*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Объекты и признаки\n",
    "\n",
    "*Признак* (feature) $f$ объекта $x$ — это результат измерения некоторой характеристики объекта. Формально признаком называется отображение $f: X \\to D_f$, где $D_f$ — множество допустимых значений признака. В частности, любой алгоритм $a: X \\to Y$ также можно рассматривать как признак. В зависимости от природы множества $D_f$ признаки делятся на несколько типов. \n",
    "\n",
    "- Если $D_f = \\{0,1\\}$, то $f$ — бинарный признак; \n",
    "- Если $D_f$ — конечное множество, то $f$ —номинальный признак; \n",
    "- Если $D_f$ — конечное упорядоченное множество, то f —порядковый признак; \n",
    "- Если $D_f = R$, то $f$ — количественный признак. \n",
    "\n",
    "Если все признаки имеют одинаковый тип, $D_{f_1} = ... = D_{f_n}$, то исходные данные называются однородными, в противном случае — разнородными. \n",
    "\n",
    "Пусть имеется набор признаков $f_1,...,f_n$. Вектор $f_1(x),...,f_n(x)$ называют признаковым описанием объекта $x \\in X$. В дальнейшем мы не будем различать объекты из $X$ и их признаковые описания, полагая $X = D_{f_1} \\times ... \\times D_{f_n}$. Совокупность признаковых описаний всех объектов выборки $X_{\\ell}$, записанную в виде таблицы размера $\\ell \\times n$, называют *матрицей объектов–признаков*: \n",
    "\n",
    "$$ F = {\\| f_j(x_i)\\|}_{\\ell \\times n} = \\left( \\begin{matrix}\n",
    "f_1(x_1) & ... & f_n(x_1)\\\\\n",
    "... & ... & ... \\\\\n",
    "f_1(x_{\\ell}) & ... & f_n(x_{\\ell})\n",
    "\\end{matrix} \\right)$$\n",
    "\n",
    "Матрица объектов–признаков является стандартным и наиболее распространённым способом представления исходных данных в прикладных задачах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Ответы и типы задач\n",
    "\n",
    "В зависимости от природы множества допустимых ответов Y задачи обучения по прецедентам делятся на следующие типы. \n",
    "\n",
    "Если Y = $\\{1,...,M\\}$, то это задача *классификации* (classiﬁcation) на $M$ непересекающихся классов. В этом случае всё множество объектов $X$ разбивается на классы $K_y = \\{x \\in X: y^*(x) = y\\}$, и алгоритм $a(x)$ должен давать ответ на вопрос «какому классу принадлежит $x$?». В некоторых приложениях классы называют образами и говорят о задаче *распознавания образов* (pattern recognition). \n",
    "\n",
    "Если $Y = \\{0,1\\}^M$, то это задача классификации на $M$ пересекающихся классов. В простейшем случае эта задача сводится к решению $M$ независимых задач классификации с двумя непересекающимися классами. \n",
    "\n",
    "Если $Y = R$, то это задача *восстановления регрессии* (regression estimation). \n",
    "\n",
    "Задачи *прогнозирования* (forecasting) являются частными случаями классификации или восстановления регрессии, когда $x \\in X$ — описание прошлого поведения объекта $x$, $y \\in Y$ — описание некоторых характеристик его будущего поведения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### Пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Классический датасет для машинного обучения \"Boston Housing Dataset\" по предсказанию цен домов содержит в себе следующие признаки:\n",
    "\n",
    "<details>\n",
    "  <summary>Список признаков домов</summary>\n",
    "    \n",
    "- CRIM - уровень преступности на душу населения по городам\n",
    "\n",
    "- ZN - доля земли под жилую застройку, зонированная под участки более 25 000 кв. Футов.\n",
    "\n",
    "- INDUS - доля коммерческих площадей на город.\n",
    "\n",
    "- CHAS - фиктивная переменная реки Чарльз (1, если участок ограничивает реку; 0 в противном случае)\n",
    "\n",
    "- NOX - концентрация оксидов азота (частей на 10 миллионов)\n",
    "\n",
    "- RM - среднее количество комнат в доме\n",
    "\n",
    "- AGE - доля занимаемых владельцами единиц, построенных до 1940 г.\n",
    "\n",
    "- DIS - взвешенные расстояния до пяти бостонских центров занятости\n",
    "\n",
    "- RAD - индекс доступности радиальных автомобильных дорог\n",
    "\n",
    "- TAX - полная ставка налога на имущество за 10 000 долларов США.\n",
    "\n",
    "- PTRATIO - соотношение учеников и учителей по городам\n",
    "\n",
    "- B - 1000 (Bk - 0,63) ^ 2, где Bk - доля черных по городам.\n",
    "\n",
    "- LSTAT - % более низкого статуса населения\n",
    "\n",
    "- MEDV - Средняя стоимость домов, занимаемых владельцами, в 1000 долларов\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Изображения представляются в виде численных матриц со значениями от 0 до 255.\n",
    "\n",
    "![image](images/images_in_computer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "RGB-изображения представляются в виде трех матриц для каждого канала: красного, зелёного и синего.\n",
    "\n",
    "![rgbimage](images/rgb_images_in_computer.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Звук в компьютере, грубо говоря, значения волны в текущий момент времени. Обычно данное представление преобразовывается в спектрограмму: каждому моменту времени соответствует набор частот, т.е. вектор, каждый элемент которого обозначает наличие или отсутствие определенной частоты.\n",
    "\n",
    "![sound](images/sound_representation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Модель алгоритмов и метод обучения \n",
    "\n",
    "*Моделью алгоритмов* называется параметрическое семейство отображений $A = \\{g(x,\\theta ) | \\theta \\in \\Theta\\}$, где $g: X \\times \\Theta \\to Y$ — некоторая фиксированная функция, $\\Theta$ — множество допустимых значений параметра $\\theta$, называемое *пространством параметров* или *пространством поиска* (search space). \n",
    "\n",
    "Процесс подбора оптимального параметра модели $\\theta$ по обучающей выборке $X_{\\ell}$ называют *настройкой* (ﬁtting) или *обучением* (training, learning) алгоритма $a \\in A$. \n",
    "\n",
    "*Метод обучения* (learning algorithm) — это отображение $\\mu : (X \\times Y )_{\\ell} \\to A$, которое произвольной конечной выборке $X^{\\ell} = (x_i,y_i)^{\\ell}_{i=1}$ ставит в соответствие некоторый алгоритм $a \\in A$. Говорят также, что метод $\\mu$ строит алгоритм a по выборке $X^{\\ell}$. Метод обучения должен допускать эффективную программную реализацию. \n",
    "\n",
    "Итак, в задачах обучения по прецедентам чётко различаются два этапа. \n",
    "\n",
    "На этапе обучения метод µ по выборке $X_{\\ell}$ строит алгоритм $a = \\mu (X_{\\ell})$. \n",
    "\n",
    "На этапе применения алгоритм $a$ для новых объектов $x$ выдаёт ответы $y = a(x)$. Этап обучения наиболее сложен. Как правило, он сводится к поиску параметров модели, доставляющих оптимальное значение заданному функционалу качества.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Функционал качества \n",
    "\n",
    "*Функция потерь* (loss function) — это неотрицательная функция $\\mathscr{L} (a,x)$, характеризующая величину ошибки алгоритма $a$ на объекте $x$. Если $\\mathscr{L}(a,x) = 0$, то ответ $a(x)$ называется *корректным*.\n",
    "\n",
    "\n",
    "*Функционал качества* алгоритма $a$ на выборке $X^{\\ell}$:\n",
    "$$ Q(a, X^{\\ell})= \\frac{1}{\\ell} \\sum_{i=1}^{\\ell} \\mathscr{L}(a,x_i).$$\n",
    "\n",
    "Функционал $Q$ называют также функционалом средних потерь или эмпирическим риском, так как он вычисляется по эмпирическим данным $(x_i, y_i)_i^l=1$. \n",
    "\n",
    "Функция потерь, принимающая только значения 0 и 1, называется бинарной. В этом случае $\\mathscr{L}(a,x) = 1$ означает, что алгоритм $a$ допускает ошибку на объекте $x$, а функционал $Q$ называется частотой ошибок алгоритма a на выборке $X^{\\ell}$. \n",
    "\n",
    "Наиболее часто используются следующие функции потерь $Y \\subseteq R:$ \n",
    "\n",
    "$\\mathscr{L}(a,x) = |a(x) \\neq y^∗(x)|$ — индикатор ошибки, обычно применяется в задачах классификации; \n",
    "\n",
    "$\\mathscr{L}(a,x) = |a(x) − y^*(x)|$ — отклонение от правильного ответа; функционал $Q$ называется средней ошибкой алгоритма $a$ на выборке $X_{\\ell}$; \n",
    "\n",
    "$\\mathscr{L}(a,x) = (a(x)−y^∗(x))^2$ — квадратичная функция потерь; функционал Q на-зывается средней квадратичной ошибкой алгоритма a на выборке $X^{\\ell}$; обычно применяется в задачах регрессии. \n",
    "\n",
    "Классический метод обучения, называемый минимизацией эмпирического риска (empirical risk minimization, ERM), заключается в том, чтобы найти в заданной модели A алгоритм a, доставляющий минимальное значение функционалу качества Q на заданной обучающей выборке $X^{\\ell}$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
